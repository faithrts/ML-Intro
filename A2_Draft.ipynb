{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faithrts/COMP-551/blob/GaryBranch/A2_Draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up"
      ],
      "metadata": {
        "id": "8A1SE2icjh69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCTCTWgB-NKG"
      },
      "outputs": [],
      "source": [
        "### importing libraries and setting the random seed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import re\n",
        "import math\n",
        "import bisect\n",
        "from scipy.stats import zscore\n",
        "from scipy.io import arff\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split as skl_train_test_split\n",
        "from sklearn.metrics import mutual_info_score\n",
        "\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "# a folder to store the saved graphs\n",
        "#!mkdir images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handling"
      ],
      "metadata": {
        "id": "hKHZWj9vjn1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "FsaKjKTqjylr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrnSxLmFTCp9",
        "outputId": "ad7462ae-ca16-409a-fc9c-67d735a8913c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 15:49:10--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  22.9MB/s    in 4.3s    \n",
            "\n",
            "2022-11-01 15:49:15 (18.6 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### importing the files from the web to google colab\n",
        "\n",
        "# retrieving the IMDB data\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "\n",
        "# unzipping the tar.gz file into google colab for easy access\n",
        "!tar -xf  'aclImdb_v1.tar.gz'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "YLKtKHXfky5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "MtAHDLEXj2T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_svmlight(matrix, vocab):\n",
        "  # boolean matrix for all values not equal to 0\n",
        "  X_boolean = matrix != 0  \n",
        "\n",
        "  # 1 X 1 matrix with the percentage of documents that includes each word (per column)\n",
        "  X_doc_percentage = X_boolean.astype(int).sum(axis = 0) / matrix.shape[0]\n",
        "\n",
        "  ''' finding the stopwords and rarewords '''\n",
        "\n",
        "  # 1 X 1 boolean matrix indicates whether each column (word) is a stopword\n",
        "  X_bool_stopwords = X_doc_percentage > 0.5\n",
        "\n",
        "  # 1 X 1 boolean matrix indicates whether each column (word) is a rareword\n",
        "  X_bool_rarewords = X_doc_percentage < 0.01\n",
        "\n",
        "  # boolean list for whether each index (word) is not a stopword\n",
        "  not_stopwords = [not word for word in X_bool_stopwords.tolist()[0]]\n",
        "\n",
        "  # boolean list for whether each index (word) is not a rare word\n",
        "  not_rarewords = [not word for word in X_bool_rarewords.tolist()[0]]\n",
        "\n",
        "  ''' finding the column indices of words that are not stopwords or rare words '''\n",
        "\n",
        "  not_stopword_indices = [index for index, x in enumerate(np.transpose(not_stopwords)) if x]\n",
        "  not_rareword_indices = [index for index, x in enumerate(np.transpose(not_rarewords)) if x]\n",
        "\n",
        "  # the intsersection of the two lists above are the indices of words that are neither\n",
        "  # stopwords nor rare words\n",
        "  not_stop_or_rare_indices = [index for index in not_stopword_indices if index in not_rareword_indices]\n",
        "\n",
        "  ''' filtering for the words that are neither stopwords nor rare words '''\n",
        "\n",
        "  # filters the original matrix\n",
        "  X_filtered = matrix[:, not_stop_or_rare_indices]\n",
        "\n",
        "  # filters the list of terms\n",
        "  vocab_filtered = [vocab[index] for index in not_stop_or_rare_indices]\n",
        "\n",
        "  return X_filtered, vocab_filtered"
      ],
      "metadata": {
        "id": "MDGNh_X8BwN4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class linear_regression:\n",
        "  def __init__(self, add_bias = True):\n",
        "    self.add_bias = add_bias\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    # if the dimension of x is 1\n",
        "    if x.ndim == 1:\n",
        "      # adds an extra dimension \n",
        "      # e.g., [1, 2, 3] -> [[1], [2], [3]]\n",
        "      x = x[:, None]\n",
        "\n",
        "    # the number of features\n",
        "    N = x.shape[0]\n",
        "\n",
        "    if self.add_bias:\n",
        "      # adds bias by adding a constant feature of value 1\n",
        "      # e.g., [[1], [2], [3]] -> [[1, 1], [2, 1], [3, 1]]\n",
        "      x = np.column_stack([x, np.ones(N)])\n",
        "\n",
        "    # w is the least square difference (w0 and w1)\n",
        "    self.w = np.linalg.lstsq(x, y)[0]\n",
        "\n",
        "    return self\n",
        "\n",
        "  def predict(self, x):\n",
        "    # the number of features\n",
        "    N = x.shape[0]\n",
        "\n",
        "    if self.add_bias:\n",
        "      # adds bias by adding a constant feature of value 1\n",
        "      # e.g., [[1], [2], [3]] -> [[1, 1], [2, 1], [3, 1]]\n",
        "      x = np.column_stack([x, np.ones(N)])\n",
        "\n",
        "    # predict the y values where @ denotes matrix multiplication\n",
        "    # y = Xw\n",
        "    yh = x @ self.w\n",
        "\n",
        "    return yh"
      ],
      "metadata": {
        "id": "KI1DkdSZVQ23"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_array(arr):\n",
        "  standardized_array = []\n",
        "\n",
        "  mean_val = arr.mean()\n",
        "  standard_dev = arr.std()\n",
        "\n",
        "  for i in arr:\n",
        "    new_val = (i - mean_val) / standard_dev\n",
        "    standardized_array.append(new_val)\n",
        "\n",
        "  return standardized_array"
      ],
      "metadata": {
        "id": "MAHNV7CbhdeQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_list(list):\n",
        "  standardized_list = []\n",
        "\n",
        "  mean_val = sum(list) / len(list)\n",
        "  standard_dev = np.std(list)\n",
        "\n",
        "  for i in list:\n",
        "    new_val = (i - mean_val) / standard_dev\n",
        "    standardized_list.append(new_val)\n",
        "\n",
        "  return standardized_list"
      ],
      "metadata": {
        "id": "qp6W-OeQkPaX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_zscores(df):\n",
        "  y = df.iloc[:, -1]\n",
        "  y_stan = standardize_list(y.tolist())\n",
        "\n",
        "  N = df.shape[0]\n",
        "\n",
        "  z_scores = []\n",
        "\n",
        "  for col in df:\n",
        "    x_stan = standardize_list(df[col].tolist())\n",
        "    col_z_score = (np.transpose(x_stan) @ y_stan) / math.sqrt(N)\n",
        "\n",
        "    z_scores.append(col_z_score)\n",
        "\n",
        "  return z_scores"
      ],
      "metadata": {
        "id": "EG8C35T2cX9c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and cleaning IMDB data"
      ],
      "metadata": {
        "id": "HQbCrZx0-EgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### loading the svm files into sparse matrices\n",
        "\n",
        "# X is the sparse matrix, y are the labels\n",
        "X_IMDB_train, y_IMDB_train = load_svmlight_file('aclImdb/train/labeledBow.feat', dtype=int)\n",
        "\n",
        "# X is the sparse matrix, y are the labels\n",
        "X_IMDB_test, y_IMDB_test = load_svmlight_file('aclImdb/test/labeledBow.feat', dtype=int)\n",
        "\n",
        "# saving a list of the terms/vocab\n",
        "IMDB_vocab = [line.rstrip() for line in open('aclImdb/imdb.vocab')]"
      ],
      "metadata": {
        "id": "QySRYXsNkWUi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### filtering the IMDB matrices to remove stop words and rare words\n",
        "\n",
        "X_IMDB_train_filtered, IMDB_train_vocab_filtered = filter_svmlight(X_IMDB_train, IMDB_vocab)\n",
        "#X_IMDB_test_filtered, IMDB_test_vocab_filtered = filter_svmlight(X_IMDB_test, IMDB_vocab)"
      ],
      "metadata": {
        "id": "Nvs7UuVlDBQ-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### creates dataframes out of the words that are neither stopwords nor rare words\n",
        "\n",
        "IMDB_train_df = pd.DataFrame(X_IMDB_train_filtered.toarray(), columns = IMDB_train_vocab_filtered)\n",
        "#IMDB_test_df = pd.DataFrame(X_IMDB_test_filtered.toarray(), columns = IMDB_test_vocab_filtered)\n",
        "\n",
        "# adds the target labels as a column\n",
        "IMDB_train_df['LABEL'] = y_IMDB_train.astype(int)\n",
        "#IMDB_test_df['LABEL'] = y_IMDB_test.astype(int)"
      ],
      "metadata": {
        "id": "cXJayRY8DL45"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_train_df"
      ],
      "metadata": {
        "id": "M7EMHNLC94ay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "01062e28-0ed6-4973-be11-e091b3869ff7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       he  his  !  by  an  who  they  from  so  like  ...  portray  length  \\\n",
              "0       0    0  1   0   0    1     0     0   0     0  ...        0       0   \n",
              "1       0    0  1   0   0    0     0     1   0     3  ...        0       0   \n",
              "2       0    0  1   0   0    0     0     1   0     0  ...        0       0   \n",
              "3       0    0  1   0   0    1     0     0   0     1  ...        0       0   \n",
              "4       0    0  0   1   1    2     0     1   0     1  ...        0       0   \n",
              "...    ..  ... ..  ..  ..  ...   ...   ...  ..   ...  ...      ...     ...   \n",
              "24995   5    0  9   3   1    7     3     2   1     0  ...        0       0   \n",
              "24996   2    2  1   0   0    1     1     1   0     2  ...        0       0   \n",
              "24997   0    2  0   2   1    2     3     1   0     3  ...        0       0   \n",
              "24998   0    1  1   0   1    0     0     0   0     0  ...        0       0   \n",
              "24999   0    0  1   0   1    0     2     0   2     0  ...        0       0   \n",
              "\n",
              "       discovered  aware  continues  below  opens  essentially  received  \\\n",
              "0               0      0          0      0      0            0         0   \n",
              "1               0      0          0      0      0            0         0   \n",
              "2               0      0          0      0      0            0         0   \n",
              "3               0      0          0      0      0            0         0   \n",
              "4               0      0          0      0      0            0         0   \n",
              "...           ...    ...        ...    ...    ...          ...       ...   \n",
              "24995           0      0          0      1      0            0         0   \n",
              "24996           0      0          0      0      0            0         0   \n",
              "24997           0      0          0      0      1            0         0   \n",
              "24998           0      0          0      0      0            0         0   \n",
              "24999           0      0          0      0      0            0         0   \n",
              "\n",
              "       LABEL  \n",
              "0          9  \n",
              "1          7  \n",
              "2          9  \n",
              "3         10  \n",
              "4          8  \n",
              "...      ...  \n",
              "24995      1  \n",
              "24996      1  \n",
              "24997      4  \n",
              "24998      2  \n",
              "24999      2  \n",
              "\n",
              "[25000 rows x 1745 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d8fe05b-b44b-4346-ac86-42dc55f30d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>he</th>\n",
              "      <th>his</th>\n",
              "      <th>!</th>\n",
              "      <th>by</th>\n",
              "      <th>an</th>\n",
              "      <th>who</th>\n",
              "      <th>they</th>\n",
              "      <th>from</th>\n",
              "      <th>so</th>\n",
              "      <th>like</th>\n",
              "      <th>...</th>\n",
              "      <th>portray</th>\n",
              "      <th>length</th>\n",
              "      <th>discovered</th>\n",
              "      <th>aware</th>\n",
              "      <th>continues</th>\n",
              "      <th>below</th>\n",
              "      <th>opens</th>\n",
              "      <th>essentially</th>\n",
              "      <th>received</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 1745 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d8fe05b-b44b-4346-ac86-42dc55f30d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d8fe05b-b44b-4346-ac86-42dc55f30d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d8fe05b-b44b-4346-ac86-42dc55f30d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and cleaning Twenty News Groups data"
      ],
      "metadata": {
        "id": "bPtGybWIk_HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### selecting 4 categories and extracting the data from sklearn\n",
        "\n",
        "fav_four = ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.politics.guns']\n",
        "\n",
        "# 20 news groups training\n",
        "twenty_train = fetch_20newsgroups(subset='train', categories=fav_four, remove=(['headers', 'footers', 'quotes']))\n",
        "# 20 news groups testing\n",
        "twenty_test = fetch_20newsgroups(subset='test', categories=fav_four, remove=(['headers', 'footers', 'quotes']))"
      ],
      "metadata": {
        "id": "3WqzrGinX5h-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1ur2Y9mBZu25"
      },
      "outputs": [],
      "source": [
        "### transforming the data into vectors\n",
        "\n",
        "# creating a new CountVectorizer object\n",
        "count_vect = CountVectorizer(max_df=0.5, min_df=0.01)\n",
        "\n",
        "# builds a dictionary of features and transforms documents to feature\n",
        "# vectors where each index represents the occurrence of a specific word\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "\n",
        "# retrieving the names of the features\n",
        "feature_names = count_vect.get_feature_names_out()\n",
        "\n",
        "# creating a dataframe in which row represents a document and each column\n",
        "# a word\n",
        "twenty_train_df = pd.DataFrame(X_train_counts.toarray(), columns = feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### adding label column\n",
        "\n",
        "twenty_train_df['LABEL'] = twenty_train.target\n",
        "\n",
        "# one-hot encoding\n",
        "twenty_train_df['LABEL'] = twenty_train_df['LABEL'].replace({0:'[1,0,0,0]', 1:'[0,1,0,0]', 2:'[0,0,1,0]', 3:'[0,0,0,1]'})"
      ],
      "metadata": {
        "id": "TEfC4SG3lEno"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining important features for IMDB data\n"
      ],
      "metadata": {
        "id": "CxLXYsHSoL5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### computing z-score of each feature\n",
        "\n",
        "# returns a list of z-scores where the value at index i is the z-score\n",
        "# of the word at column i in the dataframe\n",
        "z_scores = compute_zscores(IMDB_train_df)\n",
        "\n",
        "# computes the absolute values of each z-score\n",
        "abs_z_scores = list(map(abs, z_scores))"
      ],
      "metadata": {
        "id": "VtEoox1yoT-P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### determining the 100 most \"important\" words based on their z-scores\n",
        "\n",
        "# the indices of the words with the greatest absolute z-scores\n",
        "top_50_zscores = np.argsort(np.array(abs_z_scores))[0:50]\n",
        "\n",
        "# the indices of words with the lowest absolute z-scores\n",
        "bottom_50_zscores = np.argsort(np.array(abs_z_scores))[::-1][0:50]\n",
        "\n",
        "# the words with the top 50 absolute z-scores\n",
        "top_50_words = [IMDB_vocab[i] for i in top_50_zscores]\n",
        "\n",
        "# the words with the bottom 50 absolute z-scores\n",
        "bottom_50_words = [IMDB_vocab[i] for i in bottom_50_zscores]"
      ],
      "metadata": {
        "id": "SuxIbpSYahZ5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### analyzing the top 50 words\n",
        "\n",
        "top_50_words"
      ],
      "metadata": {
        "id": "iwTNLldPgsz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd711ce-dda4-4922-e8e8-44bdf3b7ea8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elements',\n",
              " 'disturbing',\n",
              " 'value',\n",
              " 'battle',\n",
              " 'content',\n",
              " 'final',\n",
              " 'etc',\n",
              " 'legend',\n",
              " 'runs',\n",
              " 'watching',\n",
              " 'stephen',\n",
              " 'question',\n",
              " 'de',\n",
              " 'heaven',\n",
              " 'park',\n",
              " 'filming',\n",
              " 'johnny',\n",
              " 'british',\n",
              " 'bloody',\n",
              " 'ago',\n",
              " 'expect',\n",
              " 'possible',\n",
              " 'giving',\n",
              " 'track',\n",
              " 'effort',\n",
              " 'political',\n",
              " 'describe',\n",
              " 'comedic',\n",
              " 'lord',\n",
              " 'incredible',\n",
              " 'powerful',\n",
              " 'air',\n",
              " 'direction',\n",
              " 'annoying',\n",
              " 'fast',\n",
              " 'flicks',\n",
              " 'delivers',\n",
              " 'surprisingly',\n",
              " 'apartment',\n",
              " 'romance',\n",
              " 'well',\n",
              " 'somehow',\n",
              " 'predictable',\n",
              " 'fell',\n",
              " 'dvd',\n",
              " 'new',\n",
              " 'kid',\n",
              " 'coming',\n",
              " 'kills',\n",
              " 'van']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### analyzing the bottom 50 words\n",
        "\n",
        "bottom_50_words"
      ],
      "metadata": {
        "id": "CLOVngj8gvYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e902aab-6cf7-4e10-ab1e-53c1ca77cd74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pacing',\n",
              " 'when',\n",
              " 'saw',\n",
              " 'dialogue',\n",
              " 'up',\n",
              " 'women',\n",
              " 'not',\n",
              " 'wrong',\n",
              " 'enjoy',\n",
              " 'job',\n",
              " 'become',\n",
              " \"don't\",\n",
              " 'all',\n",
              " 'tries',\n",
              " 'given',\n",
              " 'year',\n",
              " 'chance',\n",
              " 'one',\n",
              " 'off',\n",
              " 'version',\n",
              " 'most',\n",
              " 'thought',\n",
              " 'overall',\n",
              " 'above',\n",
              " 'because',\n",
              " 'keep',\n",
              " 'title',\n",
              " 'came',\n",
              " 'guess',\n",
              " 'shown',\n",
              " 'first',\n",
              " 'for',\n",
              " 'worst',\n",
              " 'dance',\n",
              " 'reason',\n",
              " 'material',\n",
              " 'japanese',\n",
              " 'trouble',\n",
              " 'story',\n",
              " 'between',\n",
              " 'child',\n",
              " 'animation',\n",
              " 'side',\n",
              " 'many',\n",
              " 'decide',\n",
              " 'success',\n",
              " 'very',\n",
              " 'age',\n",
              " 'here',\n",
              " 'honest']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining important features for Twenty News Groups data"
      ],
      "metadata": {
        "id": "dmePJk6JfKDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here gary\n",
        "#The actual usefulness of a feature depends on the model you use it with. \n",
        "#A feature is only useful to the extent that its relationship with the target is one your model can learn. \n",
        "#Just because a feature has a high MI score doesn't mean your model will be able to do anything with that information. \n",
        "#You may need to transform the feature first to expose the association.\n",
        "\n",
        "def make_MI_scores(Labels_true, Labels_pred):\n",
        "  mi_scores = mutual_info_score(Labels_true, Labels_pred)\n",
        "  return mi_scores\n",
        "\n",
        "def show_MI_scores(mi_scores, class_label):\n",
        "  show_scores = pd.Series(mi_scores, name = \"Mutual Info Scores of \" + str(class_label))\n",
        "  show_scores = show_scores.sort_values(ascending=False)\n",
        "  show_scores = show_scores[0:25] #shows the first 25 features with the highest MI scores\n",
        "  \n",
        "  return show_scores\n",
        "\n",
        "def top25_union(score1,score2,score3,score4):\n",
        "  union = []\n",
        "  for i in range(25):\n",
        "    union.append(score1[i])\n",
        "    union.append(score2[i])\n",
        "    union.append(score3[i])\n",
        "    union.append(score4[i])\n",
        "  union = pd.unique(union)\n",
        "  return union  "
      ],
      "metadata": {
        "id": "KB6myfMNfWw6"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp1 = twenty_train_df.copy()\n",
        "temp2 = twenty_train_df.copy()\n",
        "temp3 = twenty_train_df.copy()\n",
        "temp4 = twenty_train_df.copy()\n",
        "\n",
        "temp1=temp1.replace({'[1,0,0,0]':1,'[0,1,0,0]':0,'[0,0,1,0]':0,'[0,0,0,1]':0})\n",
        "temp2=temp2.replace({'[1,0,0,0]':0,'[0,1,0,0]':1,'[0,0,1,0]':0,'[0,0,0,1]':0})\n",
        "temp3=temp3.replace({'[1,0,0,0]':0,'[0,1,0,0]':0,'[0,0,1,0]':1,'[0,0,0,1]':0})\n",
        "temp4=temp4.replace({'[1,0,0,0]':0,'[0,1,0,0]':0,'[0,0,1,0]':0,'[0,0,0,1]':1})\n",
        "\n",
        "temp1 = temp1.iloc[:, -1]\n",
        "temp2 = temp2.iloc[:, -1]\n",
        "temp3 = temp3.iloc[:, -1]\n",
        "temp4 = temp4.iloc[:, -1]\n",
        "\n",
        "temp1 = temp1.to_numpy()\n",
        "temp2 = temp2.to_numpy()\n",
        "temp3 = temp3.to_numpy()\n",
        "temp4 = temp4.to_numpy()"
      ],
      "metadata": {
        "id": "qb08fLsMF30o"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MI_scores_class1 = []\n",
        "MI_scores_class2 = []\n",
        "MI_scores_class3 = []\n",
        "MI_scores_class4 = []\n",
        "\n",
        "\n",
        "for col in twenty_train_df.iloc[:,:-1]:\n",
        "  col_list = twenty_train_df[col].tolist()\n",
        "  MI_scores_class1.append(make_MI_scores(temp1, col_list))\n",
        "  #MI_scores_class2.append(make_MI_scores(temp2, col_list))\n",
        "  #MI_scores_class3.append(make_MI_scores(temp3, col_list))\n",
        "  #MI_scores_class4.append(make_MI_scores(temp4, col_list))\n",
        "\n",
        "descendingScores1 = show_MI_scores(MI_scores_class1, \"class1\")\n",
        "#descendingScores2 = show_MI_scores(MI_scores_class2, \"class2\")\n",
        "#descendingScores3 = show_MI_scores(MI_scores_class3, \"class3\")\n",
        "#descendingScores4 = show_MI_scores(MI_scores_class4, \"class4\")\n",
        "\n",
        "print(descendingScores1)\n",
        "#print(descendingScores1[0])\n",
        "#print(descendingScores2)\n",
        "#print(descendingScores3)\n",
        "#print(descendingScores4)\n",
        "\n",
        "#bestFeatures = top25_union(descendingScores1,descendingScores2,descendingScores3,descendingScores4)\n",
        "#print(bestFeatures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Jpy3vvxwGQ",
        "outputId": "d29d3834-9563-4358-c680-4680309f547e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "594     0.055424\n",
            "167     0.038482\n",
            "1122    0.035078\n",
            "216     0.031178\n",
            "169     0.030452\n",
            "168     0.025874\n",
            "709     0.025395\n",
            "205     0.022661\n",
            "1123    0.022051\n",
            "867     0.021807\n",
            "1516    0.020717\n",
            "1253    0.020108\n",
            "710     0.019664\n",
            "224     0.018578\n",
            "147     0.018363\n",
            "717     0.018044\n",
            "866     0.016067\n",
            "914     0.015848\n",
            "603     0.015728\n",
            "1170    0.015239\n",
            "1055    0.015205\n",
            "281     0.014243\n",
            "250     0.014191\n",
            "493     0.014163\n",
            "612     0.013993\n",
            "Name: Mutual Info Scores of class1, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train_df"
      ],
      "metadata": {
        "id": "gs1Y3l1iyjd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Labels_true = twenty_train_df.data\n",
        "\n",
        "mi_scores = make_MI_scores(Labels_true, Labels_pred)\n",
        "mi_scores[::3]"
      ],
      "metadata": {
        "id": "r83Pe8wAxE4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing models"
      ],
      "metadata": {
        "id": "a6lVueablnwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "U_WEPKULlIU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression"
      ],
      "metadata": {
        "id": "-7B0imbhlxBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class regression"
      ],
      "metadata": {
        "id": "vFWDVUnTl3gR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running experiments"
      ],
      "metadata": {
        "id": "IlELJSq3nWUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "0rywH03KE_9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression experiments"
      ],
      "metadata": {
        "id": "SNenEnbonsLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy tests"
      ],
      "metadata": {
        "id": "v2F28zoKwHvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class regression experiments"
      ],
      "metadata": {
        "id": "MPKaxl_Ynx2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline accuracy tests\n"
      ],
      "metadata": {
        "id": "_Wj_V05NvwBf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8A1SE2icjh69",
        "FsaKjKTqjylr",
        "CxLXYsHSoL5K"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}